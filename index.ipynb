{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for filesystem access\n",
    "import os\n",
    "# for Unix filename pattern matching\n",
    "import fnmatch\n",
    "# for data analysis\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LINGSPAM_BARE_DATASET_PATH = \"datasets/lingspam_public/bare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_spam_file_name(file_name):\n",
    "    return fnmatch.fnmatchcase(file_name, 'spmsg*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read all the emails in the ten folders & save the labels (spam/not spam, or 0/1) of each email to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for root, dirs, file_names in os.walk(LINGSPAM_BARE_DATASET_PATH):\n",
    "    for file_name in fnmatch.filter(file_names, '*.txt'):\n",
    "        with open(os.path.join(root, file_name), 'r') as file:\n",
    "            documents.append(file.read())\n",
    "            labels.append(1 if is_spam_file_name(file_name) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Read 2893 documents\n"
     ]
    }
   ],
   "source": [
    "documents_length = len(documents)\n",
    "\n",
    "if documents_length > 0:\n",
    "    print(\"‚úÖ Read %i documents\" % len(documents))\n",
    "else:\n",
    "    print(\"‚ùå Could not read any documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the emails & labels into 80% training & 20% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_documents_count = round(documents_length * 0.8)\n",
    "\n",
    "training_documents = documents[:training_documents_count]\n",
    "training_labels = labels[:training_documents_count]\n",
    "\n",
    "testing_documents = documents[training_documents_count:]\n",
    "testing_labels = labels[training_documents_count:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and transform the training emails & transform the testing emails using a CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit(training_documents)\n",
    "\n",
    "training_document_term_matrix = count_vectorizer.transform(training_documents)\n",
    "testing_document_term_matrix = count_vectorizer.transform(testing_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn Classifiers\n",
    "##### For each classifier, print the precision, recall and f-score on the testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Naive Bayes classifier precision score: 0.970874\n",
      "üîé Naive Bayes classifier recall score: 0.993776\n",
      "üîé Naive Bayes classifier f-score: 0.981868\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_classifier = MultinomialNB(alpha=1) # alpha: additive smoothing parameter\n",
    "naive_bayes_classifier.fit(training_document_term_matrix, training_labels)\n",
    "\n",
    "naive_bayes_classifier_predictions = naive_bayes_classifier.predict(testing_document_term_matrix)\n",
    "\n",
    "naive_bayes_classifier_precision_score = metrics.precision_score(testing_labels, naive_bayes_classifier_predictions, average='macro')\n",
    "naive_bayes_classifier_recall_score = metrics.recall_score(testing_labels, naive_bayes_classifier_predictions, average='macro')\n",
    "naive_bayes_classifier_f1_score = metrics.f1_score(testing_labels, naive_bayes_classifier_predictions, average='macro')\n",
    "\n",
    "print(\"üîé Naive Bayes classifier precision score: %f\" % naive_bayes_classifier_precision_score)\n",
    "print(\"üîé Naive Bayes classifier recall score: %f\" % naive_bayes_classifier_recall_score)\n",
    "print(\"üîé Naive Bayes classifier f-score: %f\" % naive_bayes_classifier_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé K Neighbors classifier precision score: 0.933640\n",
      "üîé K Neighbors classifier recall score: 0.908190\n",
      "üîé K Neighbors classifier f-score: 0.920282\n"
     ]
    }
   ],
   "source": [
    "kneighbors_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "kneighbors_classifier.fit(training_document_term_matrix, training_labels)\n",
    "\n",
    "kneighbors_classifier_predictions = kneighbors_classifier.predict(testing_document_term_matrix)\n",
    "\n",
    "kneighbors_classifier_precision_score = metrics.precision_score(testing_labels, kneighbors_classifier_predictions, average='macro')\n",
    "kneighbors_classifier_recall_score = metrics.recall_score(testing_labels, kneighbors_classifier_predictions, average='macro')\n",
    "kneighbors_classifier_f1_score = metrics.f1_score(testing_labels, kneighbors_classifier_predictions, average='macro')\n",
    "\n",
    "print(\"üîé K Neighbors classifier precision score: %f\" % kneighbors_classifier_precision_score)\n",
    "print(\"üîé K Neighbors classifier recall score: %f\" % kneighbors_classifier_recall_score)\n",
    "print(\"üîé K Neighbors classifier f-score: %f\" % kneighbors_classifier_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "##### you can set random_state=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Random Forest classifier precision score: 0.977228\n",
      "üîé Random Forest classifier recall score: 0.881443\n",
      "üîé Random Forest classifier f-score: 0.921097\n"
     ]
    }
   ],
   "source": [
    "random_forest_classifier = RandomForestClassifier(random_state=0)\n",
    "random_forest_classifier.fit(training_document_term_matrix, training_labels)\n",
    "\n",
    "random_forest_classifier_predictions = random_forest_classifier.predict(testing_document_term_matrix)\n",
    "\n",
    "random_forest_classifier_precision_score = metrics.precision_score(testing_labels, random_forest_classifier_predictions, average='macro')\n",
    "random_forest_classifier_recall_score = metrics.recall_score(testing_labels, random_forest_classifier_predictions, average='macro')\n",
    "random_forest_classifier_f1_score = metrics.f1_score(testing_labels, random_forest_classifier_predictions, average='macro')\n",
    "\n",
    "print(\"üîé Random Forest classifier precision score: %f\" % random_forest_classifier_precision_score)\n",
    "print(\"üîé Random Forest classifier recall score: %f\" % random_forest_classifier_recall_score)\n",
    "print(\"üîé Random Forest classifier f-score: %f\" % random_forest_classifier_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying using Readability Features\n",
    "\n",
    "Rather than using the whole text content of an email, some characteristic features can be extracted per email, that will be fed to the classifier. Extract some features. The features are:\n",
    "\n",
    "    a) F1: The number of sentences in an email.\n",
    "    b) F2: The number of verbs in an email.\n",
    "    c) F3: The number of words containing both numeric and alphabetical characters.\n",
    "    d) F4: The number of words in an email that are found in the spam list.\n",
    "    e) F5: The number of words in an email that have more than 3 syllables.\n",
    "    f) F6: The average number of syllables of words in an email.\n",
    "    \n",
    "For F2, you can find useful code in Lab Assignment 5 solution on the MET website. For F4, you will be checking how many words in a given email are found in a spam word-list. The word-list you will be using can be found here. For F5 and F6, you can use the library Pyphen (with lang=‚Äôen_GB‚Äô).\n",
    "\n",
    "The steps are:\n",
    "\n",
    "    a) Create a list for every feature, where every element is the feature value of a given email (or use a\n",
    "    dictionary, key is feature name, value is feature list).\n",
    "    b) Build a feature matrix (list of lists), where every row corresponds to an email, and every column\n",
    "    corresponds to a feature value of this email.\n",
    "    c) Feed the feature matrix and the labels to any of the sklearn classifiers.\n",
    "    \n",
    "On the MET website, you will find a file titled ‚Äúfeature-construction‚Äù. This is an example of building a\n",
    "feature matrix (steps ‚Äúa‚Äù and ‚Äúb‚Äù). Note that this is just a sample, the documents and the features to be\n",
    "extracted will be different in the project.\n",
    "\n",
    "##### For the classifier, print the precision, recall and f-score on the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1: The number of sentences in an email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "import nltk.tokenize as tokenizer\n",
    "\n",
    "f1 = [len(tokenizer.sent_tokenize(document)) for document in documents]\n",
    "print(f1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F2: The number of verbs in an email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "docstags = [pos_tag(word_tokenize(document)) for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbsNr (tags):\n",
    "    filtered = set() \n",
    "    for (word, tag) in tags:\n",
    "        if(tag == 'VB'):\n",
    "            filtered.add(word)\n",
    "    return len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "f2 = [verbsNr (tags) for tags in docstags]\n",
    "print(f2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F3: The number of words containing both numeric and alphabetical characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg = '/^\\w+$/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a feature matrix (list of lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 19]\n"
     ]
    }
   ],
   "source": [
    "feat_matrix = [[f1[i], f2[i]] for i in range(len(documents))]\n",
    "print(feat_matrix[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
